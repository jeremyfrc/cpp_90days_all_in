## 为什么 SoA 会提升 Cache Hit Rate？
想象你要计算一亿个粒子的速度。你的算法只需要访问所有粒子的 x 坐标进行更新。

### AoS (你的 Vector3D 类数组)：内存布局是 xyzxyzxyz...。
当你读取第一个粒子的 x 时，CPU 会把一整块内存（Cache Line，通常 64 字节）加载到缓存里。这块内存里包含了该粒子的 y 和 z。但你的算法现在不需要它们。你浪费了宝贵的缓存空间和带宽去加载暂时不用的数据。

### SoA (三个独立数组)：内存布局是 xxxx..., yyyy..., zzzz...。
当你读取 x[0] 时，缓存里加载的全是后续的 x[1], x[2], x[3]...。每一比特被搬运到 CPU 的数据都是接下来要用的。缓存污染极低，命中率极高。

## 另一个隐藏的大招：SIMD
更重要的是，SoA 布局是 矢量化 (Vectorization) 的前提。现代 CPU 的 SIMD 指令可以一次性处理 4 个或 8 个 double。

### 在 SoA 布局下，CPU 可以一次加载 4 个 x 进行并行运算。

### 在 AoS 布局下，数据是跳跃的，CPU 很难进行这种自动优化。

## 🛠️ 架构抉择
虽然 SoA 性能更强，但它的缺点是代码写起来比较别扭（不再是 particle.x，而是 x_array[i]）。

在大师级 C++ 开发中，我们通常会使用 “Data-Oriented Design” (面向数据设计)：
内部存储使用 SoA：为了极致的计算速度。
外部接口模拟 AoS：通过重载运算符或迭代器，让用户看起来像是在操作一个个独立的 Vector3D 对象。


